{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from tvm import autotvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -arch=sm_70 -max_num_threads=1024 -thread_warp_size=32, workload=('dyconv/masker', 1, 1, 64, 56, 56, 2). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotune log/c64_w56_g16/maskconv.json complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -arch=sm_70 -max_num_threads=1024 -thread_warp_size=32, workload=('dyconv/masker', 1, 1, 64, 56, 56, 4). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotune log/c64_w56_g16/maskconv.json complete!\n",
      "autotune log/c64_w56_g16/maskconv.json complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -arch=sm_70 -max_num_threads=1024 -thread_warp_size=32, workload=('dyconv/masker', 1, 1, 64, 56, 56, 8). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotune log/c64_w56_g16/maskconv.json complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -arch=sm_70 -max_num_threads=1024 -thread_warp_size=32, workload=('dyconv/masker', 1, 1, 64, 56, 56, 14). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotune log/c64_w56_g16/maskconv.json complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=cuda -keys=cuda,gpu -arch=sm_70 -max_num_threads=1024 -thread_warp_size=32, workload=('dyconv/masker', 1, 1, 64, 56, 56, 28). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotune log/c64_w56_g16/maskconv.json complete!\n",
      "autotune log/c64_w56_g16/maskconv.json complete!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'log/c128_w28_g16/maskconv.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=38'>39</a>\u001b[0m args\u001b[39m=\u001b[39m[batch_size,granul_groups,channel,width,height,granul_size]\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=39'>40</a>\u001b[0m task \u001b[39m=\u001b[39m autotvm\u001b[39m.\u001b[39mtask\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=40'>41</a>\u001b[0m     task_name\u001b[39m=\u001b[39mtask_name, args\u001b[39m=\u001b[39margs, target\u001b[39m=\u001b[39mtarget\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=41'>42</a>\u001b[0m ) \u001b[39m# Create a tuning task and initialize its search space\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=42'>43</a>\u001b[0m \u001b[39mwith\u001b[39;00m autotvm\u001b[39m.\u001b[39;49mapply_history_best(save_path):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=43'>44</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tvm\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mTarget(target):\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6479636f6e765f736572766572222c2273657474696e6773223a7b22686f7374223a227373683a2f2f646778227d7d/root/dynconv-performance-benchmark-cpu/masker/test_sch_result.ipynb#ch0000001vscode-remote?line=44'>45</a>\u001b[0m         s, arg_bufs \u001b[39m=\u001b[39m masker_conv(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913+gae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py:201\u001b[0m, in \u001b[0;36mApplyHistoryBest.__init__\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=197'>198</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_best_user_defined \u001b[39m=\u001b[39m {}\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=199'>200</a>\u001b[0m \u001b[39mif\u001b[39;00m records:\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=200'>201</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload(records)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913+gae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py:229\u001b[0m, in \u001b[0;36mApplyHistoryBest.load\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=225'>226</a>\u001b[0m best_by_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_by_model\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=227'>228</a>\u001b[0m counter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=228'>229</a>\u001b[0m \u001b[39mfor\u001b[39;00m inp, res \u001b[39min\u001b[39;00m records:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=229'>230</a>\u001b[0m     counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/task/dispatcher.py?line=230'>231</a>\u001b[0m     \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39merror_no \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913+gae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py:210\u001b[0m, in \u001b[0;36mload_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=196'>197</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_file\u001b[39m(filename):\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=197'>198</a>\u001b[0m     \u001b[39m\"\"\"Generator: load records from file.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=198'>199</a>\u001b[0m \u001b[39m    This is a generator that yields the records.\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=199'>200</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=207'>208</a>\u001b[0m \u001b[39m    result: autotvm.measure.MeasureResult\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=208'>209</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=209'>210</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=210'>211</a>\u001b[0m         \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m f:\n\u001b[1;32m    <a href='file:///usr/local/lib/python3.8/dist-packages/tvm-0.9.dev913%2Bgae285c6f0-py3.8-linux-x86_64.egg/tvm/autotvm/record.py?line=211'>212</a>\u001b[0m             \u001b[39mif\u001b[39;00m row \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m row\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'log/c128_w28_g16/maskconv.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import autotvm\n",
    "import tvm.te as te\n",
    "import tvm.testing\n",
    "from masker_scheduler import *\n",
    "\n",
    "gpu_id=1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = f'{gpu_id}'\n",
    "refresh=0 # clear prev search\n",
    "target=\"cuda\"\n",
    "device=tvm.device(target, 0)\n",
    "task_name=\"dyconv/masker\"\n",
    "\n",
    "# widths, channels, group_width = regnet_parameters(\"008\")\n",
    "# regnet 008\n",
    "widths = [56, 28, 14, 7]\n",
    "channels = [64, 128, 288, 672]\n",
    "group_width = 16\n",
    "batch_size=1\n",
    "\n",
    "test_densities = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "for density in test_densities:\n",
    "    for i in range(4):\n",
    "        width, channel = widths[i], channels[i]\n",
    "        height=width\n",
    "        n_trial = 300\n",
    "        eval_repeat=100\n",
    "        granul_groups=1\n",
    "        save_dir = f\"log/c{channel}_w{width}_g{group_width}\"\n",
    "        \n",
    "        granul_sizes = get_factors(width)\n",
    "        for granul_size in granul_sizes:\n",
    "            n_blocks = find_best_n_blocks(width//granul_size, density-0.01, density+0.01)\n",
    "            save_path=f\"{save_dir}/maskconv.json\"\n",
    "            args=[batch_size,granul_groups,channel,width,height,granul_size]\n",
    "            task = autotvm.task.create(\n",
    "                task_name=task_name, args=args, target=target\n",
    "            ) # Create a tuning task and initialize its search space\n",
    "            with autotvm.apply_history_best(save_path):\n",
    "                with tvm.target.Target(target):\n",
    "                    s, arg_bufs = masker_conv(*args)\n",
    "                    func = tvm.build(s, arg_bufs)\n",
    "                    \n",
    "                    evaluator=func.time_evaluator(func.entry_name,device,eval_repeat)\n",
    "                    input = np.random.randn(batch_size, channel, height, width).astype(\"float32\")\n",
    "                    weight = np.random.randn(granul_groups, channel).astype(\"float32\")\n",
    "                    output = np.zeros([batch_size,granul_groups,height//granul_size,width//granul_size]).astype(\"float32\")\n",
    "                    sample=[input, weight,output]\n",
    "                    sample = [tvm.nd.array(_, device) for _ in sample]\n",
    "                    t=evaluator(*sample).mean\n",
    "                    with open(save_path+'.best','w') as f:\n",
    "                        f.write(f\"time {t} \\n\")\n",
    "                        f.write(f\"{tvm.lower(s, arg_bufs, simple_mode=True)}\")\n",
    "                        \n",
    "            # measure_option = autotvm.measure_option(\n",
    "            #     builder=autotvm.LocalBuilder(),\n",
    "            #     runner=autotvm.LocalRunner(repeat=3, min_repeat_ms=150, timeout=4),\n",
    "            # )\n",
    "            # tuner = autotvm.tuner.XGBTuner(task)\n",
    "            # tuner.tune(\n",
    "            #     n_trial=n_trial,\n",
    "            #     measure_option=measure_option,\n",
    "            #     callbacks=[autotvm.callback.log_to_file(save_path)],\n",
    "            # )\n",
    "            print(f\"autotune {save_path} complete!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
